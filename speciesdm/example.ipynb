{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biogeodataframe import BioGeoDataFrame\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "from rioxarray.merge import merge_arrays\n",
    "from geocube.api.core import make_geocube\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CRS to BC Albers\n",
    "CRS = 'EPSG:3005'\n",
    "BUFFER_DISTANCE = 10000 # in units of CRS\n",
    "GEOCUBE_RES = 5000\n",
    "N_SAMPLES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in species occurrence data as a geodataframe and remove non-georeferenced rows\n",
    "species_tmp = gpd.read_file('../data/black_bear_occurrences.csv')\n",
    "species_tmp = species_tmp[(species_tmp['decimalLatitude'] != '') & (species_tmp['decimalLongitude'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the geopandas to a BioGeoDataFrame, giving access to useful methods\n",
    "N = np.nanmin((N_SAMPLES, species_tmp.shape[0]))\n",
    "species = BioGeoDataFrame(species_tmp).sample(N)\n",
    "species = species.set_geometry(gpd.points_from_xy(\n",
    "        species['decimalLongitude'], species['decimalLatitude'])).set_crs(4326)\n",
    "species = species.to_crs(CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in biogeoclimatic zones and reproject to desired CRS\n",
    "# Use only the ZONE and geometry fields, the former of which is what we will predict species' distributions with\n",
    "bec_tmp = gpd.read_file('../data/bec').to_crs(CRS)\n",
    "bec_tmp = bec_tmp[['ZONE', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables must be made numeric to be transformed into a raster, so must convert numbers back to strings\n",
    "# To do this, create list of all strings\n",
    "bec_zones = bec_tmp.ZONE.drop_duplicates().values.tolist()\n",
    "categorical_enums = {'ZONE': bec_zones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bec geodataframe to rioxarray raster\n",
    "# Resolution is in the units of target CRS\n",
    "bec = make_geocube(vector_data = bec_tmp, resolution=(GEOCUBE_RES, -GEOCUBE_RES), categorical_enums=categorical_enums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(bec['ZONE']))\n",
    "# print(np.unique(bec['ZONE'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric back to categorical string\n",
    "zone_string = bec['ZONE_categories'][bec['ZONE'].astype(int)].drop('ZONE_categories')\n",
    "bec['ZONE'] = zone_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pseudo-absences\n",
    "pres_abs = species.add_pseudo_absences(amount=species.shape[0], region_poly=bec_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of raster tiles, find which ones intersect the species occurrence points and are therefore required\n",
    "# Using a single raster, bec, for simplicity\n",
    "rasters = pres_abs.which_rasters(BUFFER_DISTANCE, [bec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of raster tiles into memory\n",
    "# Would load the rasters here, but bec is already loaded for simplicity. Something like:\n",
    "# rasters = [rioxarray.open_rasterio(x) for x in raster]\n",
    "# merged_raster = merge_arrays(rasters)\n",
    "merged_raster = bec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Buffer each point so it intersects adjacent raster cells\n",
    "pres_abs['buffered_geometry'] = pres_abs['geometry'].buffer(BUFFER_DISTANCE, cap_style=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_raster.rio.clip(geometries=pres_abs['buffered_geometry'][0]).dims\n",
    "# [x.dims for x in merged_raster.rio.clip(geometries=pres_abs['buffered_geometry'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_raster.rio.crs == pres_abs.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occurrence point, build a 3D tensor \n",
    "vals = pres_abs.extract_values(merged_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.stack([x['arr'] for x in vals if x['arr'] is not None and 'nodata' not in x['arr']])\n",
    "y_train = np.stack([x['presence'] for x in vals if x['arr'] is not None and 'nodata' not in x['arr']])\n",
    "\n",
    "original, int_array = np.unique(x_train, return_inverse=True)\n",
    "\n",
    "# x_train = int_array\n",
    "# original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  # tf.keras.layers.Input(shape=(1,)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# len(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.dtype for x in np.asarray(x_train, dtype='float64')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.fit(x_train, y_train, batch_size=32, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
